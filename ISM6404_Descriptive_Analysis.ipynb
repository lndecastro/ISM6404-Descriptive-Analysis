{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addd9864",
   "metadata": {},
   "source": [
    "# ISM 6404: BI and Data Visualization\n",
    "# Descriptive Analysis\n",
    "## Prof. Leandro Nunes de Castro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This content was created as a supporting material for the course\n",
    "# ISM 6404 - BI and Data Visualization\n",
    "# Prof. Leandro de Castro (c), Spring 2024\n",
    "# All rights reserved\n",
    "\n",
    "# Florida Gulf Coast University"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8c812",
   "metadata": {},
   "source": [
    "# 1. Frequency Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the frequency distribution, frequency table and pie chart \n",
    "# of variable 'Shape' in the Mammographic dataset\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading dataset1\n",
    "# https://archive.ics.uci.edu/ml/datasets/Mammographic+Mass\n",
    "dmammo = pd.read_csv('mammographic_masses_nominal.csv')\n",
    "print(dmammo.head) # Print the first and last 5 rows\n",
    "\n",
    "SShape = pd.Series(dmammo['Shape'])\n",
    "ftable = SShape.value_counts()  # Generate the frequency table\n",
    "rftable = ftable/len(SShape)*100  # Relative frequency\n",
    "cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency\n",
    "df = pd.DataFrame({'Frequency':ftable.to_list(),\n",
    "                   'Relative Frequency':rftable.to_list(),\n",
    "                  'Cumulative Frequency':cftable.to_list()})\n",
    "print(df)\n",
    "fig, figftable = plt.subplots()\n",
    "\n",
    "# Using a color palette with different levels of the same color\n",
    "colors = sns.color_palette(\"Blues\", len(ftable))[::-1]\n",
    "\n",
    "# Plotting the pie chart with the new color palette\n",
    "figftable.pie(ftable.to_list(), labels=ftable.index.to_list(),\n",
    "              autopct='%1.2f%%', colors=colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0309d8",
   "metadata": {},
   "source": [
    "**CW 1**: Do a search and find out what are the libraries: Pandas, Matplotlib, and Seaborn\n",
    "\n",
    "**CW 2**: Test the code above for other variables of the mammographic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d807c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the frequency distribution, frequency table and histogram \n",
    "# of continuous variables in the Forest Fire dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loading dataset2\n",
    "# https://archive.ics.uci.edu/ml/datasets/forest+fires\n",
    "dforest = pd.read_csv('forestfires.csv')\n",
    "print(dforest.head) # Print the first and last 5 rows\n",
    "\n",
    "var = 'temp'  # Choose the target variable\n",
    "SShape = pd.Series(dforest[var])\n",
    "nbins = 10\n",
    "inflimit = 0; suplimit = max(SShape)\n",
    "ampl = (suplimit - inflimit)/nbins\n",
    "\n",
    "# Define the range of the variable and bin size\n",
    "fbins = np.arange(0,suplimit+ampl,ampl)\n",
    "\n",
    "# The pandas.cut function groups the data into bins and counts \n",
    "# the frequency\n",
    "ftable = pd.cut(SShape,fbins).value_counts() # Absolute frequency\n",
    "rftable = ftable/len(SShape)*100  # Relative frequency\n",
    "cftable = ftable.cumsum()/len(SShape)*100  # Cumulative frequency\n",
    "df = pd.DataFrame({'Bins':ftable.index.to_list(),\n",
    "                   'Frequency':ftable.to_list(),\n",
    "                   'Relative Frequency':rftable.to_list(),\n",
    "                   'Cumulative Frequency':cftable.to_list()})\n",
    "print(df)\n",
    "plt.xticks(fbins)\n",
    "sns.histplot(dforest,x=var,bins=fbins, kde = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dec2db",
   "metadata": {},
   "source": [
    "**CW 3**: Test the code above for other variables of the forest fires dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions with different shapes \n",
    "# Load the forest fires dataset from UCI\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "\n",
    "sns.histplot(dforest,x='month',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='day',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='FFMC',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='DMC',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='DC',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='ISI',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='RH',bins='auto', kde = 2); plt.show()\n",
    "sns.histplot(dforest,x='wind',bins='auto', kde = 2); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e9c67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot distributions with different shapes \n",
    "# Load the forest fires dataset from UCI\n",
    "# Alternative implementation\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "var = ['month','day','FFMC','DMC','DC','ISI','RH','wind']\n",
    "for i in var:\n",
    "    sns.histplot(dforest,x=i,bins='auto', kde = 2); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Contingency Tables for the Mammographic Dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mammographic-masses/mammographic_masses.data\"\n",
    "cols = ['BI-RADS', 'Age', 'Shape', 'Margin', 'Density', 'Severity']\n",
    "dmammo = pd.read_csv(url, names=cols, na_values='?')\n",
    "\n",
    "# Remove rows with missing values\n",
    "dmammo.dropna(inplace=True)\n",
    "\n",
    "# Print the contingency tables\n",
    "var = ['Shape','Margin','Density']\n",
    "print('**Contingency Tables**')\n",
    "for i in var:\n",
    "    CT = pd.crosstab(dmammo[i], dmammo['Severity'])\n",
    "    print('Variables',i, 'and Severity:\\n',CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c9a010",
   "metadata": {},
   "source": [
    "# 2. Summary Measures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93874220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean and mode one by one using the Statistics library\n",
    "# Numeric variables\n",
    "\n",
    "import statistics as st\n",
    "\n",
    "print('**Forest Fires Dataset**')\n",
    "print('\\n*Numeric Variable FFMC*')\n",
    "print('Mean of variable FFMC: {:.2f}'.format(st.mean(dforest['FFMC'])))\n",
    "print('Median of variable FFMC: {:.2f}'.format(st.median(dforest['FFMC'])))\n",
    "midpoint = (max(dforest['FFMC'])+min(dforest['FFMC']))/2\n",
    "print('Midpoint of variable FFMC: {:.2f}'.format(midpoint))\n",
    "\n",
    "print('\\n*Numeric Variable temp*')\n",
    "print('Mean of variable temp: {:.2f}'.format(st.mean(dforest['temp'])))\n",
    "print('Median of variable temp: {:.2f}'.format(st.median(dforest['temp'])))\n",
    "midpoint = (max(dforest['temp'])+min(dforest['temp']))/2\n",
    "print('Midpoint of variable temp: {:.2f}'.format(midpoint))\n",
    "\n",
    "# Nominal variables\n",
    "print('\\n*Categorical Variables*')\n",
    "print('Mode of nominal variable month: {v1}'\n",
    "      .format(v1=st.mode(dforest['month'])))\n",
    "print('Mode of nominal variable day: {v1}'\n",
    "      .format(v1=st.mode(dforest['day'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590ce7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the central tendency measures over the histogram \n",
    "\n",
    "import statistics as st\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "var = 'temp'  # Choose the target variable\n",
    "mean = st.mean(dforest[var])\n",
    "median = st.median(dforest[var])\n",
    "midpoint = (max(dforest[var])+min(dforest[var]))/2\n",
    "print('Mean, median and midpoint for temp:',mean,median,midpoint)\n",
    "sns.histplot(dforest,x=var,bins='auto', kde = 2)\n",
    "plt.axvline(x=mean, color='r', linestyle='--', label='Mean')\n",
    "plt.axvline(x=median, color='g', linestyle='-', label='Median')\n",
    "plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')\n",
    "plt.legend() # Add a legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate z-scores for 'temp'\n",
    "dforest['temp_zscore'] = (dforest['temp'] - dforest['temp'].mean()) / dforest['temp'].std()\n",
    "\n",
    "# Print z-scores for specific values of 'temp' with two decimal places\n",
    "temp_values = [5, 10, 15, 20, 25, 30]\n",
    "for value in temp_values:\n",
    "    z_score = round((value - dforest['temp'].mean()) / dforest['temp'].std(), 2)\n",
    "    print(f\"Z-score for temp value {value}: {z_score}\")\n",
    "\n",
    "# Plot vertically oriented boxplot for 'temp'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(y='temp', data=dforest, orient='v')\n",
    "plt.title('Boxplot for Variable temp')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab35fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the weighted average, geometric, harmonic, and trimmed means\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as spy\n",
    "\n",
    "var = 'FFMC'\n",
    "weights = np.random.randn(len(dforest[var]))\n",
    "wavg = np.average(dforest[var], weights=weights)\n",
    "gavg = spy.gmean(dforest[var])  # From Scipy library\n",
    "havg = spy.hmean(dforest[var])  # From Scipy library\n",
    "tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim\n",
    "\n",
    "print('Weighted average of variable FFMC: {:.2f}'.format(wavg))\n",
    "print('Geometric mean of variable FFMC: {:.2f}'.format(gavg))\n",
    "print('Harmonic mean of variable FFMC: {:.2f}'.format(havg))\n",
    "print('Trimmed mean of variable FFMC: {:.2f}'.format(tavg))\n",
    "\n",
    "var = 'temp'\n",
    "weights = np.random.randn(len(dforest[var]))\n",
    "wavg = np.average(dforest[var], weights=weights)\n",
    "gavg = spy.gmean(dforest[var])  # From Scipy library\n",
    "havg = spy.hmean(dforest[var])  # From Scipy library\n",
    "tavg = spy.trim_mean(dforest[var],0.05)  # 5% trim\n",
    "\n",
    "print('\\nWeighted average of variable temp: {:.2f}'.format(wavg))\n",
    "print('Geometric mean of variable temp: {:.2f}'.format(gavg))\n",
    "print('Harmonic mean of variable temp: {:.2f}'.format(havg))\n",
    "print('Trimmed mean of variable temp: {:.2f}'.format(tavg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10af41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central Tendency Measures for the Forest Fires Dataset\n",
    "# Columns of interest: 'FFMC','DMC','DC', 'ISI', 'temp', 'RH', 'wind', 'rain'\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as spy\n",
    "\n",
    "ffmc = dforest['FFMC']; dmc = dforest['DMC']; dc = dforest['DC']\n",
    "isi = dforest['ISI']; temp = dforest['temp']; rh = dforest['RH']\n",
    "wind = dforest['wind']; rain = dforest['rain']\n",
    "\n",
    "# Dictionary to store the results\n",
    "CTM = {}\n",
    "\n",
    "# Loop over the columns and calculate the statistics\n",
    "for col_name, col_data in zip(['FFMC','DMC','DC', 'ISI', 'temp', 'RH', 'wind', 'rain'],\n",
    "                              [ffmc, dmc, dc, isi, temp, rh, wind, rain]):\n",
    "    mean = np.mean(col_data)\n",
    "    median = np.median(col_data)\n",
    "    midpoint = (np.max(col_data) + np.min(col_data)) / 2\n",
    "    wavg = np.average(col_data, weights=dforest['area'])\n",
    "    gavg = spy.gmean(col_data)\n",
    "    havg = spy.hmean(col_data)\n",
    "    tavg = spy.trim_mean(col_data, proportiontocut=0.1)\n",
    "    # Add the results to the dictionary\n",
    "    CTM[col_name] = {'Mean': mean,\n",
    "                         'Median': median,\n",
    "                         'Midpoint': midpoint,\n",
    "                         'Weighted Mean': wavg,\n",
    "                         'Geometric Mean': gavg,\n",
    "                         'Harmonic Mean': havg,\n",
    "                         'Trimmed Mean': tavg}\n",
    "    \n",
    "# Print the results\n",
    "for col_name, col_results in CTM.items():\n",
    "    print(col_name)\n",
    "    for stat_name, stat_value in col_results.items():\n",
    "        print(f\"\\t{stat_name}: {stat_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4bedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variability measures range, \n",
    "# IQR, sIQR, variance, std, and CV using Numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "var = 'FFMC'\n",
    "drange = np.max(dforest[var]) - np.min(dforest[var])\n",
    "Q1, Q3 = np.percentile(dforest[var], [25,75])\n",
    "IQR = Q3 - Q1\n",
    "sIQR = IQR / 2\n",
    "dvar = np.var(dforest[var])\n",
    "dstd = np.std(dforest[var])\n",
    "CV = dstd / np.mean(dforest[var]) * 100\n",
    "\n",
    "print('*Variability Measures*')\n",
    "print('Range of variable FFMC: {:.2f}'.format(drange))\n",
    "print('IQR of variable FFMC: {:.2f}'.format(IQR))\n",
    "print('sIQR of variable FFMC: {:.2f}'.format(sIQR))\n",
    "print('Variance of variable FFMC: {:.2f}'.format(dvar))\n",
    "print('Standard deviation of variable FFMC: {:.2f}'.format(dstd))\n",
    "print('Variation coefficient of variable FFMC: {:.2f}'.format(CV))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab87004",
   "metadata": {},
   "source": [
    "**CW 4**: For the Auto MPG dataset, do:\n",
    "1. Calculate the central tendency measures for all variables, numerical and categorical.\n",
    "2. Plot the frequency distribution of all numerical variables and the central tendency values of the histogram\n",
    "3. Plot the boxplot for all independent variables\n",
    "4. Calculate the variability measures for all independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e067188",
   "metadata": {},
   "source": [
    "# 3. Measures of Shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ba4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Skewed distributions\n",
    "# Generate random data with a right-skewed distribution\n",
    "\n",
    "import statistics as st\n",
    "import numpy as np \n",
    "from scipy.stats import skew\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "data = np.random.beta(a=1, b=5, size=1000) # Beta distribution\n",
    "mean = st.mean(data)\n",
    "median = st.median(data)\n",
    "mode = st.mode(data)\n",
    "print('Mean, median and mode: {:.2f} {:.2f} {:.2f}'\n",
    "      .format(mean,median,mode))\n",
    "print('Skewness (Fischer-Pearson Coefficient): {:.2f}'\n",
    "      .format(skew(data)))\n",
    "print('Skewness (First Skewness Coefficient): {:.2f}'\n",
    "      .format((mean-mode)/np.std(data)))\n",
    "sns.histplot(data,bins='auto', kde = 2)\n",
    "plt.axvline(x=mean, color='r', linestyle='--', label='Mean')\n",
    "plt.axvline(x=median, color='g', linestyle='-', label='Median')\n",
    "plt.axvline(x=mode, color='b', linestyle=':', label='Mode')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness and Skewed distributions\n",
    "# Generate random data with a left-skewed distribution\n",
    "\n",
    "import statistics as st\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_neg = np.random.beta(a=5, b=1, size=1000)  # Beta distribution\n",
    "mean = st.mean(data_neg)\n",
    "median = st.median(data_neg)\n",
    "midpoint = (max(data_neg) + min(data_neg)) / 2  # Calculate the midpoint\n",
    "print('Mean, median, and midpoint: {:.2f} {:.2f} {:.2f}'\n",
    "      .format(mean, median, midpoint))\n",
    "print('Skewness (Fischer-Pearson Coefficient): {:.2f}'\n",
    "      .format(skew(data_neg)))\n",
    "print('Skewness (First Skewness Coefficient): {:.2f}'\n",
    "      .format((mean - midpoint) / np.std(data_neg)))\n",
    "sns.histplot(data_neg, bins='auto', kde=2)\n",
    "plt.axvline(x=mean, color='r', linestyle='--', label='Mean')\n",
    "plt.axvline(x=median, color='g', linestyle='-', label='Median')\n",
    "plt.axvline(x=midpoint, color='b', linestyle=':', label='Midpoint')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f083eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis: mesokurtic, platykurtic and leptokurtic distributions\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm, laplace, semicircular, kurtosis\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normal distribution (Mesokurtic)\n",
    "dnorm = norm.rvs(size=10000)\n",
    "k = kurtosis(dnorm)\n",
    "print('Kurtosis: {:.2f}'.format(k))\n",
    "sns.histplot(dnorm, bins='auto', kde=2)\n",
    "plt.title(f\"Normal Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Uniform distribution (Platykurtic)\n",
    "dunif = np.random.uniform(0.01, 0.10, 10000)\n",
    "k = kurtosis(dunif)\n",
    "print('Kurtosis: {:.2f}'.format(k))\n",
    "sns.histplot(dunif, bins='auto', kde=2)\n",
    "plt.title(f\"Uniform Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Laplace distribution (Leptokurtic)\n",
    "dlap = laplace.rvs(loc=0, scale=1, size=10000)\n",
    "k = kurtosis(dlap)\n",
    "sns.histplot(dlap, bins='auto', kde=2)\n",
    "plt.title(f\"Laplace Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()\n",
    "\n",
    "# Wigner semicircle distribution\n",
    "dwigner = semicircular.rvs(size=10000)\n",
    "k = kurtosis(dwigner)\n",
    "sns.histplot(dwigner, bins='auto', kde=2)\n",
    "plt.title(f\"Wigner Semicircle Distribution - Kurtosis: {k:.2f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Skewness and Kurtosis for the Forest Fires variables\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# load dataset\n",
    "dforest = pd.read_csv(\"forestfires.csv\")\n",
    "\n",
    "# Skewness and kurtosis for each variable\n",
    "skewness = dforest[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']].skew()\n",
    "kurt = dforest[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']].kurtosis()\n",
    "\n",
    "# Print the results and classify the kurtosis\n",
    "for var in skewness.index:\n",
    "    print(f\"{var} Skewness: {skewness[var]:.2f}\")\n",
    "    if kurt[var] > 0:\n",
    "        print(f\"{var} Kurtosis: {kurt[var]:.2f} (Leptokurtic)\")\n",
    "    elif kurt[var] < 0:\n",
    "        print(f\"{var} Kurtosis: {kurt[var]:.2f} (Platykurtic)\")\n",
    "    else:\n",
    "        print(f\"{var} Kurtosis: {kurt[var]:.2f} (Mesokurtic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c11d1f",
   "metadata": {},
   "source": [
    "**CW 5**: For the Iris dataset, calculate the Skewness and Kurtosis for the independent variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4d756b",
   "metadata": {},
   "source": [
    "# 4. Measures of Association "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the Covariance Matrix of the Forest Fires dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dforest = pd.read_csv('forestfires.csv')\n",
    "\n",
    "# Select the desired numeric features\n",
    "features = ['X','Y','FFMC','DMC','DC','ISI','temp','RH','wind','rain']\n",
    "\n",
    "# Compute the covariance matrix and format to two decimal places\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "Mcov = dforest[features].cov()\n",
    "\n",
    "# Print the covariance matrix\n",
    "print(Mcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Correlation Coefficients: PCC, SRCC and KRCC\n",
    "# for the numerical variables of the Forest Fires dataset\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "# Read the data into a pandas dataframe\n",
    "dforest = pd.read_csv(\"forestfires.csv\")\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Calculate PCC, SRCC, KRCC\n",
    "print('**Forest Fires Dataset: PCC, SRCC, KRCC**')\n",
    "PCC = dforest.corr(method='pearson')\n",
    "print('Pearson Correlation Coefficient (PCC)\\n',PCC)\n",
    "SRCC = dforest.corr(method='spearman')\n",
    "print('\\nSpearman Rank Correlation Coefficient (SRCC)\\n',SRCC)\n",
    "KRCC = dforest.corr(method='kendall')\n",
    "print('\\nKramers Rank Correlation Coefficient (KRCC)\\n',KRCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f634c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots between pairs of variables from the Forest Fires dataset\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "\n",
    "# Extract the relevant columns\n",
    "cols = ['DMC', 'DC', 'FFMC', 'ISI', 'temp', 'RH', 'wind', 'area', 'rain']\n",
    "dforest = dforest[cols]\n",
    "df = dforest\n",
    "\n",
    "# Generate the scatter plots\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(12, 12))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "axs[0, 0].scatter(df['DMC'], df['DC'], alpha=0.5)\n",
    "axs[0, 0].set_xlabel('DMC'); axs[0, 0].set_ylabel('DC')\n",
    "axs[0, 0].set_title('PCC: {:.2f}'.format(df['DMC'].corr(df['DC'], method='pearson')))\n",
    "axs[0, 1].scatter(dforest['FFMC'], dforest['ISI'], alpha=0.5)\n",
    "axs[0, 1].set_xlabel('FFMC'); axs[0, 1].set_ylabel('ISI')\n",
    "axs[0, 1].set_title('PCC: {:.2f}'.format(df['FFMC'].corr(df['ISI'], method='pearson')))\n",
    "axs[1, 0].scatter(dforest['temp'], dforest['RH'], alpha=0.5)\n",
    "axs[1, 0].set_xlabel('temp'); axs[1, 0].set_ylabel('RH')\n",
    "axs[1, 0].set_title('PCC: {:.2f}'.format(df['temp'].corr(df['RH'], method='pearson')))\n",
    "axs[1, 1].scatter(dforest['temp'], dforest['wind'], alpha=0.5)\n",
    "axs[1, 1].set_xlabel('temp'); axs[1, 1].set_ylabel('wind')\n",
    "axs[1, 1].set_title('PCC: {:.2f}'.format(df['temp'].corr(df['wind'], method='pearson')))\n",
    "axs[2, 0].scatter(dforest['wind'], dforest['area'], alpha=0.5)\n",
    "axs[2, 0].set_xlabel('wind'); axs[2, 0].set_ylabel('area')\n",
    "axs[2, 0].set_title('PCC: {:.2f}'.format(df['wind'].corr(df['area'], method='pearson')))\n",
    "axs[2, 1].scatter(dforest['rain'], dforest['DC'], alpha=0.5)\n",
    "axs[2, 1].set_xlabel('rain'); axs[2, 1].set_ylabel('DC')\n",
    "axs[2, 1].set_title('PCC: {:.2f}'.format(df['rain'].corr(df['DC'], method='pearson')))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmap\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix using Cramer's V\n",
    "corr_matrix = dmammo.corr(method='kendall')\n",
    "\n",
    "# Create the heatmap using seaborn\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee411fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the scatterplot matrix\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Extract the relevant columns\n",
    "cols = ['DMC', 'DC', 'FFMC', 'ISI', 'temp', 'RH', 'wind', 'area', 'rain']\n",
    "df = df[cols]\n",
    "\n",
    "# Create a scatterplot matrix\n",
    "pd.plotting.scatter_matrix(df[['DMC', 'DC', 'FFMC', 'ISI', 'temp', 'RH', 'wind', 'area', 'rain']],\n",
    "                           alpha=0.2, figsize=(12, 12), diagonal='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d2dfe",
   "metadata": {},
   "source": [
    "**CW 6**: For the independent variables of the Iris dataset, do:\n",
    "1. Calculate and print the covariance matrix.\n",
    "2. Calculate and print the correlation coefficient matrix.\n",
    "3. Plot the scatterplot for all pairs of independent variables.\n",
    "4. Plot the heatmap of the correlation matrix.\n",
    "5. Plot the scatterplot matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d21f2c",
   "metadata": {},
   "source": [
    "## Extra Code: All Variables at Once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba7e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the data using the describe() method from the Pandas library\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
    "dforest = pd.read_csv(url)\n",
    "\n",
    "print('Forest Fires Dataset\\n')\n",
    "print('Numerical variables \\n',dforest.describe().round(2))\n",
    "print('\\nNominal variable: month \\n',dforest['month'].describe())\n",
    "print('\\nNominal variable: day \\n',dforest['day'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
